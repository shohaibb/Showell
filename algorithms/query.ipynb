{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('igdb_games.json', 'r') as file:\n",
    "    games = json.load(file)\n",
    "    \n",
    "with open('igdb_keywords.json', 'r') as file:\n",
    "    keywords = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_CHINA = \"\"\n",
    "query_EGYPT = \"\"\n",
    "query_GREECE = \"\"\n",
    "query_JAPAN = \"\"\n",
    "query_MIDDLEEAST = \"\"\n",
    "query_NORWAY = \"\"\n",
    "query_ROME = \"\"\n",
    "\n",
    "with open('culture_term_lists/china.txt') as file:\n",
    "    for line in file:\n",
    "        query_CHINA += line.strip() + \" \"\n",
    "\n",
    "with open('culture_term_lists/egypt.txt') as file:\n",
    "    for line in file:\n",
    "        query_EGYPT += line.strip() + \" \"\n",
    "        \n",
    "with open('culture_term_lists/greece.txt') as file:\n",
    "    for line in file:\n",
    "        query_GREECE += line.strip() + \" \"\n",
    "        \n",
    "with open('culture_term_lists/japan.txt') as file:\n",
    "    for line in file:\n",
    "        query_JAPAN += line.strip() + \" \"\n",
    "        \n",
    "with open('culture_term_lists/middle_east.txt') as file:\n",
    "    for line in file:\n",
    "        query_MIDDLEEAST += line.strip() + \" \"\n",
    "        \n",
    "with open('culture_term_lists/norway.txt') as file:\n",
    "    for line in file:\n",
    "        query_NORWAY += line.strip() + \" \"\n",
    "        \n",
    "with open('culture_term_lists/rome.txt') as file:\n",
    "    for line in file:\n",
    "        query_ROME += line.strip() + \" \"\n",
    "        \n",
    "query_LGBTQ = \"\"\n",
    "query_NEURODIVERGENT = \"\"\n",
    "\n",
    "with open('identity_term_lists/lgbtq.txt') as file:\n",
    "    for line in file:\n",
    "        query_LGBTQ += line.strip() + \" \"\n",
    "        \n",
    "with open('identity_term_lists/neurodivergent.txt') as file:\n",
    "    for line in file:\n",
    "        query_NEURODIVERGENT += line.strip() + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning keywords into a dictionary for later use\n",
    "keywords_dict = {}\n",
    "for keyword in keywords:\n",
    "    keywords_dict[keyword['id']] = keyword['name']\n",
    "\n",
    "letters = \"abcdefghijklmnopqrstuvwxyz-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# 1. Concatenating storyline, summary, and keywords\n",
    "# 2. Only allowing lowercase letters + hyphen\n",
    "\n",
    "# GAME ID -> TEXT\n",
    "CLEANED_DATA = {}\n",
    "\n",
    "for game in games:\n",
    "    FULL_TEXT = \"\" #FULL GAME TEXT\n",
    "    GAME_TEXT = \"\" #FINAL GAME TEXT\n",
    "    \n",
    "    if 'summary' in game:\n",
    "        FULL_TEXT += game['summary'] + \" \"\n",
    "        \n",
    "    if 'storyline' in game:\n",
    "        FULL_TEXT += game['storyline'] + \" \"\n",
    "        \n",
    "    if 'keywords' in game:\n",
    "        KEYWORD_LIST = game['keywords']\n",
    "        for keyword_id in KEYWORD_LIST:\n",
    "            FULL_TEXT += ''.join(keywords_dict[keyword_id].split()) + \" \"\n",
    "            \n",
    "    for word in FULL_TEXT.split():\n",
    "        CURRENT_WORD = ''.join(char for char in word.lower() if char in letters)\n",
    "        if len(CURRENT_WORD) > 0:\n",
    "            GAME_TEXT += CURRENT_WORD + \" \"\n",
    "            \n",
    "    if len(GAME_TEXT) > 0:\n",
    "        CLEANED_DATA[game['id']] = GAME_TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259218, 185430)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "GAME_IDS = list(CLEANED_DATA.keys())\n",
    "GAME_TEXTS = list(CLEANED_DATA.values())\n",
    "\n",
    "VECTORIZER = TfidfVectorizer()\n",
    "TFIDF_MATRIX = VECTORIZER.fit_transform(GAME_TEXTS)\n",
    "\n",
    "print(TFIDF_MATRIX.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector_CHINA = VECTORIZER.transform([query_CHINA])\n",
    "query_vector_EGYPT = VECTORIZER.transform([query_EGYPT])\n",
    "query_vector_GREECE = VECTORIZER.transform([query_GREECE])\n",
    "query_vector_JAPAN = VECTORIZER.transform([query_JAPAN])\n",
    "query_vector_MIDDLEEAST = VECTORIZER.transform([query_MIDDLEEAST])\n",
    "query_vector_NORWAY = VECTORIZER.transform([query_NORWAY])\n",
    "query_vector_ROME = VECTORIZER.transform([query_ROME])\n",
    "query_vector_LGBTQ = VECTORIZER.transform([query_LGBTQ])\n",
    "query_vector_NEURODIVERGENT = VECTORIZER.transform([query_NEURODIVERGENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarities_CHINA = cosine_similarity(query_vector_CHINA, TFIDF_MATRIX)\n",
    "similarities_EGYPT = cosine_similarity(query_vector_EGYPT, TFIDF_MATRIX)\n",
    "similarities_GREECE = cosine_similarity(query_vector_GREECE, TFIDF_MATRIX)\n",
    "similarities_JAPAN = cosine_similarity(query_vector_JAPAN, TFIDF_MATRIX)\n",
    "similarities_MIDDLEEAST = cosine_similarity(query_vector_MIDDLEEAST, TFIDF_MATRIX)\n",
    "similarities_NORWAY = cosine_similarity(query_vector_NORWAY, TFIDF_MATRIX)\n",
    "similarities_ROME = cosine_similarity(query_vector_ROME, TFIDF_MATRIX)\n",
    "similarities_LGBTQ = cosine_similarity(query_vector_LGBTQ, TFIDF_MATRIX)\n",
    "similarities_NEURODIVERGENT = cosine_similarity(query_vector_NEURODIVERGENT, TFIDF_MATRIX)\n",
    "\n",
    "games_ranked_CHINA = similarities_CHINA.argsort()[0][::-1]\n",
    "games_ranked_EGYPT = similarities_EGYPT.argsort()[0][::-1]\n",
    "games_ranked_GREECE = similarities_GREECE.argsort()[0][::-1]\n",
    "games_ranked_JAPAN = similarities_JAPAN.argsort()[0][::-1]\n",
    "games_ranked_MIDDLEEAST = similarities_MIDDLEEAST.argsort()[0][::-1]\n",
    "games_ranked_NORWAY = similarities_NORWAY.argsort()[0][::-1]\n",
    "games_ranked_ROME = similarities_ROME.argsort()[0][::-1]\n",
    "games_ranked_LGBTQ = similarities_LGBTQ.argsort()[0][::-1]\n",
    "games_ranked_NEURODIVERGENT = similarities_NEURODIVERGENT.argsort()[0][::-1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
